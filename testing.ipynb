{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-to-Text Model form GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "## Load the Groq API\n",
    "groq_api_key = os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(groq_api_key=groq_api_key, model_name = \"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"where is tajmahal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Taj Mahal is located in Agra, Uttar Pradesh, India. It's situated on the southern bank of the Yamuna River, about 200 kilometers (124 miles) south of the national capital, New Delhi.\n",
      "\n",
      "The Taj Mahal is a UNESCO World Heritage Site and one of the Seven Wonders of the Modern World. It was built by Mughal Emperor Shah Jahan as a mausoleum for his beloved wife, Mumtaz Mahal, who died in childbirth in 1631. The construction of the Taj Mahal began in 1632 and took around 22 years to complete.\n",
      "\n",
      "Today, the Taj Mahal is one of the most famous and iconic landmarks in India, attracting millions of visitors every year.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio-to-Text Wishper Model From GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import io\n",
    "def convert_to_wav(audio_file_path):\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "    audio = audio.set_channels(1).set_frame_rate(16000)  # Mono-channel, 16kHz\n",
    "    buffer = io.BytesIO()\n",
    "    audio.export(buffer, format=\"wav\")\n",
    "    wav_bytes = buffer.getvalue()  # Get the audio in bytes\n",
    "    return wav_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key, model_name = \"whisper-large-v3\")\n",
    "audio_bytes = convert_to_wav(\"sample2.flac\")\n",
    "response = llm.invoke(audio_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " before he had time to answer a much-encumbered vera burst into the room with the question i say can i leave these here these were a small black pig and a lusty specimen of black-red game cock\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq()\n",
    "\n",
    "# Specify the path to the audio file\n",
    "filename = \"sample2.flac\" # Replace with your audio file!\n",
    "\n",
    "# Open the audio file\n",
    "with open(filename, \"rb\") as file:\n",
    "    # Create a translation of the audio file\n",
    "    translation = client.audio.translations.create(\n",
    "      file=(filename, file.read()), # Required audio file\n",
    "      model=\"whisper-large-v3\", # Required model to use for translation\n",
    "      prompt=\"Specify context or spelling\",  # Optional\n",
    "      response_format=\"json\",  # Optional\n",
    "      temperature=0.0  # Optional\n",
    "    )\n",
    "    # Print the translation text\n",
    "    print(translation.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image-to-Text LLaVA V1.5 7B (Preview) from GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A calm cat is sitting on a white surface. It appears large and has an orange coat, with its head cocked to one side, giving a somewhat creepy look. The cat has a long tail that makes up most of its body.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"CAT.jpeg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"caption this image\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    model=\"llava-v1.5-7b-4096-preview\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
